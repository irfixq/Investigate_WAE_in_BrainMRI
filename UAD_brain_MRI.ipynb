{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6cjIFrxl4xpb"
   },
   "source": [
    "# Unsupervised Anomaly Detection Brain-MRI\n",
    "\n",
    "Jupyter notebook for running all the experiments from our [paper](https://arxiv.org/abs/2004.03271). \n",
    "\n",
    "Hyperparameters may have to be adjusted!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xYcltK7e6r5A"
   },
   "source": [
    "## Preperation\n",
    "\n",
    "### Imports and installation of the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LI-mX3ic4zBC"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# from google.colab import files\n",
    "import os, glob\n",
    "! pip install pynrrd\n",
    "! pip install SimpleITK\n",
    "! pip install bunch\n",
    "! pip install nibabel\n",
    "! pip install medpy\n",
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xlBFG8cb9zRr"
   },
   "source": [
    "### Get Code\n",
    "Clone Code from github.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BmL1urt8-F1a"
   },
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/irfixq/Investigate_WAE_in_BrainMRI\n",
    "# ! cd Investigate_WAE_in_BrainMRI/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uo5Rut3WcSHH"
   },
   "source": [
    "### Google Drive mount\n",
    "Mounting Google Drive to access datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBFA_7f5cUe0"
   },
   "outputs": [],
   "source": [
    "# drive.mount('gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Irfixq\\\\Desktop\\\\P2\\\\Code 1\\\\Unsupervised_Anomaly_Detection_Brain_MRI-master'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wRn8HOi7rSvV"
   },
   "source": [
    "### Tensorboard and tunneling\n",
    "Install ngrok for tunneling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sc71w6qerQtF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"ngrok-stable-linux-amd64.zip\"):\n",
    "    os.remove(\"ngrok-stable-linux-amd64.zip\")\n",
    "\n",
    "if os.path.exists(\"ngrok\"):\n",
    "    os.remove(\"ngrok\")\n",
    "  \n",
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wQ6JZY18fS4G"
   },
   "source": [
    "Start tensorboard and forward port with ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kele9MJBfAVK"
   },
   "outputs": [],
   "source": [
    "LOG_DIR = 'logs/'\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "\n",
    "get_ipython().system_raw('./ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8fGr1nvVqduU"
   },
   "source": [
    "Extract ngrok url for accessing tensorboard\n",
    "\n",
    "**Attention**: Sometimes it throws an error like this:\n",
    "```\n",
    "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
    "```\n",
    "If this is the case the easiest way to solve this issue is to delete the ngrok*.zip and ngrok from the Google Drive folder and install them again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rOJxnfekqPg2"
   },
   "outputs": [],
   "source": [
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tensorflow==1.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o8QsqbYA53MI"
   },
   "source": [
    "## Training\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m1xgAd-K4Q30"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 1.x\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "from utils.default_config_setup import get_config, get_options, get_datasets\n",
    "from trainers.AE import AE\n",
    "from trainers.VAE import VAE\n",
    "from trainers.CE import CE\n",
    "from trainers.ceVAE import ceVAE\n",
    "from trainers.GMVAE import GMVAE\n",
    "from trainers.fAnoGAN import fAnoGAN\n",
    "from trainers.AnoVAEGAN import AnoVAEGAN\n",
    "from trainers.WAE import WAEGAN\n",
    "from models import autoencoder, variational_autoencoder, context_encoder_variational_autoencoder,gaussian_mixture_variational_autoencoder,fanogan,constrained_autoencoder,anovaegan, WAEGAN\n",
    "from utils import Evaluation\n",
    "from utils.default_config_setup import get_config, get_options, get_datasets, Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xogLARJl_B0K"
   },
   "source": [
    "Set paths to datasets and where to save checkpoints and evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GgkGf2LO35hI"
   },
   "outputs": [],
   "source": [
    "def get_CONFIG(timestamp=None):\n",
    "  current_time = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "  if timestamp:\n",
    "    current_time=timestamp\n",
    "  dataset_root = \"C:/Users/Irfixq/Desktop/P2/Code 1/Unsupervised_Anomaly_Detection_Brain_MRI-master\"\n",
    "  save_dir = \"C:/Users/Irfixq/Desktop/P2/Code 1/Unsupervised_Anomaly_Detection_Brain_MRI-master\"\n",
    "  CONFIG = {\n",
    "    \"BRAINWEBDIR\": os.path.join(dataset_root, 'Brainweb'),\n",
    "    \"CHECKPOINTDIR\": os.path.join(save_dir, 'checkpoints', current_time),\n",
    "    \"SAMPLEDIR\": os.path.join(save_dir, 'sample_dir', current_time),\n",
    "  }\n",
    "  return CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L41jcwBrqkev"
   },
   "source": [
    "### Manual Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1-a9c5c4qaiK"
   },
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Q8IFuKHqEiI"
   },
   "source": [
    "**AE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IBobdPWvXBsl"
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=AE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = AE(tf.Session(), config, network=autoencoder.autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-pIg1uHQufK"
   },
   "source": [
    "**VAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ia25A9wli8d6"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=VAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = VAE(tf.Session(), config, network=variational_autoencoder.variational_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2WmjqCqp3S4"
   },
   "source": [
    "#### ceVAE - Variations\n",
    "\n",
    "Paper: [Context-encoding Variational Autoencoder for Unsupervised Anomaly Detection](https://arxiv.org/abs/1812.05941)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AsxKL2xIXhrL"
   },
   "source": [
    "**CE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ed4PbNOc2P50"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.Brainweb\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=CE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = CE(tf.Session(), config, network=autoencoder.autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XlPoFhpyLgqs"
   },
   "source": [
    "**ceVAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ujv7TbWVuA5"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.Brainweb\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=ceVAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.use_gradient_based_restoration = 0.002\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = ceVAE(tf.Session(), config, network=context_encoder_variational_autoencoder.context_encoder_variational_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ruwGvgCnuPQ8"
   },
   "source": [
    "**VAE-Zimmerer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtNu_izGM8FO"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=64, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=VAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = VAE(tf.Session(), config, network=variational_autoencoder_Zimmerer.variational_autoencoder_Zimmerer)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9lhvpN6mu7QT"
   },
   "source": [
    "**ceVAE-Zimmerer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szrN4m0eu6xM"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.Brainweb\n",
    "options = get_options(batchsize=64, learningrate=0.0001, numEpochs=1, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=ceVAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = ceVAE(tf.Session(), config, network=context_encoder_variational_autoencoder_Zimmerer.context_encoder_variational_autoencoder_Zimmerer)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Oc6ISRcqJMI"
   },
   "source": [
    "#### GMVAE-(Restoration)-Variations\n",
    "\n",
    "Paper: [Unsupervised Lesion Detection via Image Restoration with a Normative Prior](https://openreview.net/forum?id=S1xg4W-leV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KZmw9-2HO61B"
   },
   "source": [
    "**VAE-You**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAF3eVrCPAdG"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=VAE_You, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.restore_lr = 1e-3\n",
    "config.restore_steps = 10\n",
    "config.tv_lambda = 0.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = VAE_You(tf.Session(), config, network=variational_autoencoder.variational_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nhllMocWpww9"
   },
   "source": [
    "**GMVAE-You**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TmRGUPN86DTX"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=GMVAE_spatial, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.dim_c = 9\n",
    "config.dim_z = 1\n",
    "config.dim_w = 1\n",
    "config.c_lambda = 1\n",
    "config.restore_lr = 1e-3\n",
    "config.restore_steps = 10\n",
    "config.tv_lambda = 1\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = GMVAE_spatial(tf.Session(), config, network=gaussian_mixture_variational_autoencoder_You.gaussian_mixture_variational_autoencoder_You)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azCAeseN3t6i"
   },
   "source": [
    "**GMVAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5HNY5v-qCxO"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=GMVAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.dim_c = 9\n",
    "config.dim_z = 128\n",
    "config.dim_w = 1\n",
    "config.c_lambda = 1\n",
    "config.restore_lr = 1e-3\n",
    "config.restore_steps = 10\n",
    "config.tv_lambda = 0.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = GMVAE(tf.Session(), config, network=gaussian_mixture_variational_autoencoder.gaussian_mixture_variational_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8_GIxM1KGN2-"
   },
   "source": [
    "**GMVAE-spatial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9G0foovGNWI"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=GMVAE_spatial, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.dim_c = 9\n",
    "config.dim_z = 1\n",
    "config.dim_w = 1\n",
    "config.c_lambda = 1\n",
    "config.restore_lr = 1e-3\n",
    "config.restore_steps = 10\n",
    "config.tv_lambda = 0.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = GMVAE_spatial(tf.Session(), config, network=gaussian_mixture_variational_autoencoder_spatial.gaussian_mixture_variational_autoencoder_spatial)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdIb36bv-yji"
   },
   "source": [
    "#### f-AnoGAN\n",
    "\n",
    "Paper: [f-AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks.](https://www.ncbi.nlm.nih.gov/pubmed/30831356)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B3h_nH3F-0PP"
   },
   "source": [
    "**Unified f-AnoGan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aj70VsVlAjIj"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=fAnoGAN, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.kappa = 1.0\n",
    "config.scale = 10.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = fAnoGAN(tf.Session(), config, network=fanogan.fanogan)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JP-2nm-jYBuQ"
   },
   "source": [
    "**f-AnoGAN - Schlegl**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hclZeagWA6Rf"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=8, learningrate=0.0001, numEpochs=2, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=fAnoGAN, options=options, optimizer='ADAM', intermediateResolutions=[16, 16], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.kappa = 1.0\n",
    "config.scale = 10.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = fAnoGAN(tf.Session(), config, network=fanogan_schlegl.fanogan_schlegl)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U0D7zuB62DR0"
   },
   "source": [
    "#### Constrained Adversarial AE\n",
    "\n",
    "Paper: [Unsupervised Detection of Lesions in Brain MRI using constrained adversarial auto-encoders](https://arxiv.org/abs/1806.04972)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yh6Tvwe02OWA"
   },
   "source": [
    "**constrained AAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YPBnr3r32LGf"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=ConstrainedAAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.scale = 10.0\n",
    "config.rho = 1.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = ConstrainedAAE(tf.Session(), config, network=constrained_adversarial_autoencoder.constrained_adversarial_autoencoder)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5mR-WjhNv0Mo"
   },
   "source": [
    "**constrained AAE Chen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_HhaHSr4Of9"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=8, learningrate=0.0001, numEpochs=2, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=ConstrainedAAE, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "config.kappa = 1.0\n",
    "config.scale = 10.0\n",
    "config.rho = 1.0\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = ConstrainedAAE(tf.Session(), config, network=constrained_adversarial_autoencoder_Chen.constrained_adversarial_autoencoder_Chen)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_aMjd0DR236b"
   },
   "source": [
    "#### AnoVAEGAN\n",
    "\n",
    "Paper: [Deep autoencoding models for unsupervised anomaly segmentation in brain MR images](https://arxiv.org/abs/1804.04488)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdHKBg3B2-6W"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dataset = Dataset.BRAINWEB\n",
    "options = get_options(batchsize=128, learningrate=0.0001, numEpochs=20, zDim=128, outputWidth=128, outputHeight=128, config=get_CONFIG())\n",
    "options['data']['dir'] = options[\"globals\"][dataset.value]\n",
    "datasetHC, datasetPC = get_datasets(options, dataset)\n",
    "config = get_config(trainer=AnoVAEGAN, options=options, optimizer='ADAM', intermediateResolutions=[8, 8], dropout_rate=0.1, dataset=datasetHC)\n",
    "\n",
    "# Create an instance of the model and train it\n",
    "model = AnoVAEGAN(tf.Session(), config, network=anovaegan.anovaegan)\n",
    "\n",
    "# Train it\n",
    "model.train(datasetHC)\n",
    "\n",
    "# Evaluate\n",
    "Evaluation.evaluate(datasetPC, model, options, description=f\"{type(datasetHC).__name__}-{options['threshold']}\", epoch=str(options['train']['numEpochs']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1XhjDLN73NC5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1-a9c5c4qaiK",
    "P2WmjqCqp3S4",
    "9Oc6ISRcqJMI",
    "qdIb36bv-yji",
    "U0D7zuB62DR0"
   ],
   "machine_shape": "hm",
   "name": "Unsupervised Anomaly Detection Brain-MRI.ipynb",
   "provenance": [
    {
     "file_id": "1SnihwKuEnP605BZEL1vdlGPA_xM6Bpgk",
     "timestamp": 1567420278659
    },
    {
     "file_id": "1Y14H2kevErX7LCln3-8yHXNQtnykb3m9",
     "timestamp": 1566387374003
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
